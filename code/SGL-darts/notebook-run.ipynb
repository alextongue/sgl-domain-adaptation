{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aktung/.conda/envs/sgl-da/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.executable # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0) \n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : search-20210211-20210211-191841\n",
      "02/11 07:18:41 PM gpu device = 0\n",
      "02/11 07:18:41 PM args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=16, cutout=False, cutout_length=16, data='../data', debug=False, drop_path_prob=0.3, epochs=50, gpu='0', grad_clip=5, init_channels=16, is_cifar100=0, is_parallel=1, layers=8, learning_rate=0.025, learning_rate1=0.025, learning_rate_min=0.001, model_path='saved_models', momentum=0.9, report_freq=50, save='search-20210211-20210211-191841', seed=2, train_portion=0.5, unrolled=False, weight_decay=0.0003, weight_lambda=1.0)\n",
      "02/11 07:18:48 PM param size of model1 = 1.930618MB\n",
      "02/11 07:18:48 PM param size of model2 = 1.930618MB\n",
      "Files already downloaded and verified\n",
      "02/11 07:18:50 PM epoch 0 lr 2.500000e-02 lr1 2.500000e-02\n",
      "02/11 07:18:50 PM genotype1 = Genotype(normal=[('dil_conv_5x5', 1), ('sep_conv_3x3', 0), ('dil_conv_3x3', 2), ('dil_conv_5x5', 1), ('avg_pool_3x3', 1), ('dil_conv_5x5', 2), ('dil_conv_3x3', 0), ('max_pool_3x3', 3)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1), ('sep_conv_5x5', 0), ('dil_conv_5x5', 0), ('sep_conv_3x3', 1), ('max_pool_3x3', 0), ('avg_pool_3x3', 2), ('sep_conv_3x3', 4), ('sep_conv_3x3', 0)], reduce_concat=range(2, 6))\n",
      "02/11 07:18:50 PM genotype2 = Genotype(normal=[('skip_connect', 0), ('dil_conv_5x5', 1), ('sep_conv_3x3', 2), ('dil_conv_5x5', 1), ('skip_connect', 3), ('skip_connect', 2), ('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 0), ('sep_conv_3x3', 1), ('dil_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('avg_pool_3x3', 4), ('sep_conv_3x3', 2)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1250, 0.1247, 0.1251, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250],\n",
      "        [0.1249, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1248, 0.1251],\n",
      "        [0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1250, 0.1251],\n",
      "        [0.1248, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251, 0.1252, 0.1251],\n",
      "        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250],\n",
      "        [0.1249, 0.1249, 0.1252, 0.1251, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1248, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1249, 0.1249, 0.1249, 0.1250, 0.1249, 0.1250, 0.1253, 0.1251],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251],\n",
      "        [0.1250, 0.1250, 0.1252, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1249, 0.1253, 0.1250, 0.1248, 0.1248, 0.1251, 0.1251, 0.1250],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1252, 0.1250, 0.1248, 0.1250, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1249, 0.1250],\n",
      "        [0.1249, 0.1248, 0.1252, 0.1247, 0.1251, 0.1249, 0.1252, 0.1251],\n",
      "        [0.1249, 0.1249, 0.1251, 0.1250, 0.1248, 0.1250, 0.1249, 0.1254],\n",
      "        [0.1251, 0.1250, 0.1250, 0.1250, 0.1252, 0.1250, 0.1249, 0.1250],\n",
      "        [0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1252, 0.1251, 0.1247, 0.1252, 0.1249, 0.1249, 0.1250],\n",
      "        [0.1251, 0.1251, 0.1251, 0.1250, 0.1247, 0.1250, 0.1251, 0.1250],\n",
      "        [0.1250, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1248],\n",
      "        [0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],\n",
      "        [0.1248, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1252, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1249, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],\n",
      "        [0.1249, 0.1249, 0.1251, 0.1251, 0.1246, 0.1251, 0.1251, 0.1251],\n",
      "        [0.1250, 0.1247, 0.1250, 0.1251, 0.1252, 0.1250, 0.1250, 0.1250]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1249, 0.1251, 0.1249, 0.1252, 0.1250, 0.1248, 0.1250, 0.1250],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1248, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1249, 0.1250],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251],\n",
      "        [0.1250, 0.1250, 0.1251, 0.1248, 0.1252, 0.1251, 0.1249, 0.1248],\n",
      "        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1249, 0.1249, 0.1250, 0.1252, 0.1250, 0.1249, 0.1251, 0.1251],\n",
      "        [0.1250, 0.1251, 0.1250, 0.1252, 0.1251, 0.1248, 0.1249, 0.1250],\n",
      "        [0.1251, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1248],\n",
      "        [0.1248, 0.1250, 0.1249, 0.1250, 0.1252, 0.1253, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1248, 0.1252, 0.1251, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1247],\n",
      "        [0.1252, 0.1250, 0.1248, 0.1250, 0.1250, 0.1249, 0.1252, 0.1248],\n",
      "        [0.1249, 0.1251, 0.1247, 0.1251, 0.1251, 0.1250, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1249, 0.1251, 0.1251, 0.1250, 0.1253, 0.1247, 0.1248, 0.1250],\n",
      "        [0.1250, 0.1248, 0.1251, 0.1250, 0.1252, 0.1250, 0.1249, 0.1250],\n",
      "        [0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249, 0.1252],\n",
      "        [0.1249, 0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1251, 0.1250],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1250, 0.1250],\n",
      "        [0.1251, 0.1249, 0.1249, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251],\n",
      "        [0.1250, 0.1250, 0.1248, 0.1251, 0.1251, 0.1251, 0.1248, 0.1251],\n",
      "        [0.1252, 0.1250, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1251, 0.1249, 0.1251, 0.1249, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250],\n",
      "        [0.1248, 0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1250, 0.1251, 0.1249, 0.1248, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1252, 0.1252, 0.1248, 0.1247, 0.1250, 0.1252]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aktung/.conda/envs/sgl-da/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:483: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/11 07:19:00 PM train 1st 000 2.502458e+00 0.000000 25.000000\n",
      "02/11 07:19:00 PM train 2nd 000 2.307324e+00 18.750000 50.000000\n",
      "02/11 07:23:12 PM train 1st 050 2.619964e+00 19.975490 69.852941\n",
      "02/11 07:23:12 PM train 2nd 050 2.673852e+00 19.362745 70.833333\n",
      "02/11 07:27:18 PM train 1st 100 2.563870e+00 21.720297 72.400990\n",
      "02/11 07:27:18 PM train 2nd 100 2.613579e+00 20.730198 72.400990\n",
      "02/11 07:31:23 PM train 1st 150 2.493756e+00 22.806291 74.213576\n",
      "02/11 07:31:23 PM train 2nd 150 2.538085e+00 22.309603 74.544702\n",
      "02/11 07:35:27 PM train 1st 200 2.465017e+00 24.284826 75.777363\n",
      "02/11 07:35:27 PM train 2nd 200 2.505555e+00 23.600746 75.621891\n",
      "02/11 07:39:32 PM train 1st 250 2.440856e+00 24.477092 76.967131\n",
      "02/11 07:39:32 PM train 2nd 250 2.463882e+00 24.003984 76.967131\n",
      "02/11 07:43:37 PM train 1st 300 2.406385e+00 25.124585 78.280731\n",
      "02/11 07:43:37 PM train 2nd 300 2.427219e+00 24.584718 78.280731\n",
      "02/11 07:47:41 PM train 1st 350 2.371714e+00 25.890313 79.166667\n",
      "02/11 07:47:41 PM train 2nd 350 2.391567e+00 25.427350 79.344729\n",
      "02/11 07:51:45 PM train 1st 400 2.350692e+00 26.402743 79.629052\n",
      "02/11 07:51:45 PM train 2nd 400 2.368287e+00 26.137781 79.940773\n",
      "02/11 07:55:43 PM train 1st 450 2.316515e+00 27.175721 80.224501\n",
      "02/11 07:55:43 PM train 2nd 450 2.332753e+00 27.050998 80.543237\n",
      "02/11 07:59:29 PM train 1st 500 2.295959e+00 27.819361 80.526447\n",
      "02/11 07:59:29 PM train 2nd 500 2.311637e+00 27.632236 80.875749\n",
      "02/11 08:03:31 PM train 1st 550 2.282234e+00 28.266788 80.898367\n",
      "02/11 08:03:31 PM train 2nd 550 2.294829e+00 28.107985 81.272686\n",
      "02/11 08:07:26 PM train 1st 600 2.257860e+00 28.722962 81.374792\n",
      "02/11 08:07:26 PM train 2nd 600 2.272121e+00 28.566972 81.749168\n",
      "02/11 08:11:12 PM train 1st 650 2.232998e+00 29.176267 81.998848\n",
      "02/11 08:11:12 PM train 2nd 650 2.246343e+00 29.013057 82.267665\n",
      "02/11 08:14:49 PM train 1st 700 2.209296e+00 30.064194 82.498217\n",
      "02/11 08:14:49 PM train 2nd 700 2.222625e+00 29.894793 82.854850\n",
      "02/11 08:18:35 PM train 1st 750 2.194644e+00 30.584221 82.797936\n",
      "02/11 08:18:35 PM train 2nd 750 2.206225e+00 30.401132 83.172437\n",
      "02/11 08:22:07 PM train 1st 800 2.182664e+00 31.171973 83.091448\n",
      "02/11 08:22:07 PM train 2nd 800 2.193705e+00 30.828652 83.419164\n",
      "02/11 08:25:38 PM train 1st 850 2.166248e+00 31.507051 83.357814\n",
      "02/11 08:25:38 PM train 2nd 850 2.179264e+00 31.066392 83.732374\n",
      "02/11 08:29:21 PM train 1st 900 2.149483e+00 31.999168 83.761099\n",
      "02/11 08:29:21 PM train 2nd 900 2.159625e+00 31.617647 84.087125\n",
      "02/11 08:33:02 PM train 1st 950 2.141196e+00 32.301525 84.003680\n",
      "02/11 08:33:02 PM train 2nd 950 2.151311e+00 31.979495 84.305994\n",
      "02/11 08:36:39 PM train 1st 1000 2.127490e+00 32.648601 84.328172\n",
      "02/11 08:36:39 PM train 2nd 1000 2.136767e+00 32.330170 84.559191\n",
      "02/11 08:40:18 PM train 1st 1050 2.114740e+00 32.980495 84.728830\n",
      "02/11 08:40:18 PM train 2nd 1050 2.121980e+00 32.683159 84.936965\n",
      "02/11 08:44:10 PM train 1st 1100 2.097732e+00 33.566076 85.007947\n",
      "02/11 08:44:10 PM train 2nd 1100 2.103395e+00 33.208447 85.240690\n",
      "02/11 08:47:55 PM train 1st 1150 2.083322e+00 34.062772 85.262815\n",
      "02/11 08:47:55 PM train 2nd 1150 2.087731e+00 33.823849 85.490877\n",
      "02/11 08:51:47 PM train 1st 1200 2.072247e+00 34.434846 85.486053\n",
      "02/11 08:51:47 PM train 2nd 1200 2.077188e+00 34.133014 85.673397\n",
      "02/11 08:55:32 PM train 1st 1250 2.062140e+00 34.762190 85.616507\n",
      "02/11 08:55:32 PM train 2nd 1250 2.066708e+00 34.397482 85.816347\n",
      "02/11 08:59:22 PM train 1st 1300 2.050228e+00 35.222905 85.799385\n",
      "02/11 08:59:22 PM train 2nd 1300 2.056810e+00 34.828978 85.977133\n",
      "02/11 09:03:23 PM train 1st 1350 2.037908e+00 35.552369 86.001110\n",
      "02/11 09:03:23 PM train 2nd 1350 2.044554e+00 35.140637 86.176906\n"
     ]
    }
   ],
   "source": [
    "%run train_search_coop --weight_lambda 1 --is_cifar100 0 --gpu 0 --batch_size 16 --is_parallel 1 --save 20210211"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgl-da",
   "language": "python",
   "name": "sgl-da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
